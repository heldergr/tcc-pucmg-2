{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python373jvsc74a57bd04143b9c6b9342c2726020891eca2bb8d0d6574ab18558731d58b7f9e44c9082d",
   "display_name": "Python 3.7.3 64-bit ('tcc-env': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Nerds Viajantes - Generate Topics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Import libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third party libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "A list of stopwords can be found in the corpus module of nltk package. We are going to try to use the portuguese version. The download code is necessary only once.\n",
    "\"\"\"\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self package code\n",
    "from repository import nerds_viajantes\n",
    "from cleanning.limpeza_texto import stemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing and modelling\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel, CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid', context='talk')\n",
    "from wordcloud import WordCloud\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "published = nerds_viajantes.read_published()"
   ]
  },
  {
   "source": [
    "## Limpeza de posts"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                count         mean          std   min     25%      50%  \\\n",
       "id             1029.0  8422.824101  3860.734536  11.0  5049.0  10527.0   \n",
       "comment_count  1029.0     3.695821     8.599599   0.0     0.0      0.0   \n",
       "n_characters   1029.0  4108.211856  6533.186527   0.0    24.0     40.0   \n",
       "\n",
       "                   75%      max  \n",
       "id             10784.0  15389.0  \n",
       "comment_count      4.0     90.0  \n",
       "n_characters    5888.0  48775.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>id</th>\n      <td>1029.0</td>\n      <td>8422.824101</td>\n      <td>3860.734536</td>\n      <td>11.0</td>\n      <td>5049.0</td>\n      <td>10527.0</td>\n      <td>10784.0</td>\n      <td>15389.0</td>\n    </tr>\n    <tr>\n      <th>comment_count</th>\n      <td>1029.0</td>\n      <td>3.695821</td>\n      <td>8.599599</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>n_characters</th>\n      <td>1029.0</td>\n      <td>4108.211856</td>\n      <td>6533.186527</td>\n      <td>0.0</td>\n      <td>24.0</td>\n      <td>40.0</td>\n      <td>5888.0</td>\n      <td>48775.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# Check document size to see if we should remove some of  them\n",
    "# Looking at character length of documents will give an indication of too short documents.\n",
    "published['n_characters'] = published['content'].str.len()\n",
    "published.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         id                date  \\\n",
       "1011  14946 2017-12-21 21:07:38   \n",
       "466    8896 2014-04-23 20:43:31   \n",
       "340    8184 2014-03-04 12:53:29   \n",
       "10      822 2012-03-28 08:35:46   \n",
       "323    5828 2013-04-15 09:00:55   \n",
       "\n",
       "                                                content  \\\n",
       "1011  Posts sobre a América Central. Veja todas as d...   \n",
       "466   Nesta seção contamos como algumas fotos de via...   \n",
       "340   Esta página reune as nossas recomendações!\\r\\n...   \n",
       "10    Quer entrar em contato com a gente? Envie um e...   \n",
       "323   <a href=\"http://www.nerdsviajantes.com/wp-cont...   \n",
       "\n",
       "                                       title  \\\n",
       "1011                                           \n",
       "466                                            \n",
       "340                             Recomendamos   \n",
       "10                                   Contato   \n",
       "323   Pesquisa - Perfil dos Leitores do Blog   \n",
       "\n",
       "                                      name            modified  comment_count  \\\n",
       "1011                                 14946 2017-12-21 21:07:38              0   \n",
       "466                                   8896 2017-12-21 21:07:38              0   \n",
       "340                           recomendamos 2016-06-22 14:56:20              0   \n",
       "10                                 contato 2016-09-08 21:28:15              0   \n",
       "323   pesquisa-perfil-dos-leitores-do-blog 2013-10-30 08:57:11              2   \n",
       "\n",
       "      n_characters  \n",
       "1011            82  \n",
       "466            134  \n",
       "340            185  \n",
       "10             462  \n",
       "323            816  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>date</th>\n      <th>content</th>\n      <th>title</th>\n      <th>name</th>\n      <th>modified</th>\n      <th>comment_count</th>\n      <th>n_characters</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1011</th>\n      <td>14946</td>\n      <td>2017-12-21 21:07:38</td>\n      <td>Posts sobre a América Central. Veja todas as d...</td>\n      <td></td>\n      <td>14946</td>\n      <td>2017-12-21 21:07:38</td>\n      <td>0</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>466</th>\n      <td>8896</td>\n      <td>2014-04-23 20:43:31</td>\n      <td>Nesta seção contamos como algumas fotos de via...</td>\n      <td></td>\n      <td>8896</td>\n      <td>2017-12-21 21:07:38</td>\n      <td>0</td>\n      <td>134</td>\n    </tr>\n    <tr>\n      <th>340</th>\n      <td>8184</td>\n      <td>2014-03-04 12:53:29</td>\n      <td>Esta página reune as nossas recomendações!\\r\\n...</td>\n      <td>Recomendamos</td>\n      <td>recomendamos</td>\n      <td>2016-06-22 14:56:20</td>\n      <td>0</td>\n      <td>185</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>822</td>\n      <td>2012-03-28 08:35:46</td>\n      <td>Quer entrar em contato com a gente? Envie um e...</td>\n      <td>Contato</td>\n      <td>contato</td>\n      <td>2016-09-08 21:28:15</td>\n      <td>0</td>\n      <td>462</td>\n    </tr>\n    <tr>\n      <th>323</th>\n      <td>5828</td>\n      <td>2013-04-15 09:00:55</td>\n      <td>&lt;a href=\"http://www.nerdsviajantes.com/wp-cont...</td>\n      <td>Pesquisa - Perfil dos Leitores do Blog</td>\n      <td>pesquisa-perfil-dos-leitores-do-blog</td>\n      <td>2013-10-30 08:57:11</td>\n      <td>2</td>\n      <td>816</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# Avalia posts menores que 20 caracteres para ver que tipo de posts são. Este codigo ja pode ser comentando porque apos avaliacao inicial eu percebi que filtrar os posts com mais de 42 caracteres seriam suficiente, o que eh feito abaixo. Sendo assim este codigo esta aqui apenas para documentacao.\n",
    "# published.query(\"n_characters<20\").sort_values('n_characters', ascending=False)\n",
    "\n",
    "# Duvida? Sera que eu deveria fazer esta contagem de caracteres apos os posts terem tags html removidas?\n",
    "\n",
    "# Ha muitos posts pequenos, que devem ser desconsiderados. Analisando estes eu percebi que os posts de papel de parede (calendario) estao entre os pequenos e fui aumentando o tamanho minimo de post ate todos serem removidos\n",
    "\n",
    "# Exclude short documents\n",
    "# 42 me pareceu ser o tamanho do maior post de calendario (papel de parede)\n",
    "# todos menores foram removidos\n",
    "published.query(\"n_characters>=42\", inplace=True)\n",
    "published.nsmallest(5, 'n_characters')"
   ]
  },
  {
   "source": [
    "## Enriquecimento\n",
    "\n",
    "Algumas paginas especiais do blog sao tratados como posts e devem ser removidas pois nao fazem parte do conteudo que queremos tratar. Sao elas:\n",
    "\n",
    "* Papel de parede: Sobraram alguns mesmo apos a remocao de textos pequenos: \n",
    "* Recomendamos: outros blogs os quais Recomendamos\n",
    "* Contato: post com informações de contato dos editores do blog\n",
    "* Quem somos: um pouco sobre os editores do blog, tambem irrelevante para levantamento de topicos\n",
    "* Pesquisa de perfil de leitores do blog\n",
    "* Posts publicados no início que agregam pouco valor ao blog (exemplo, post da India)\n",
    "* Posts patrocinados. Analisar melhor mas a principio preferimos remover\n",
    "* Posts temporais: posts que tiveram valor apenas na epoca. Um exemplo disso eh o post do convite de nossa exposicao de fotos de parques nacionais americanos, que fizemos em bar de belo horizonte\n",
    "\n",
    "A Analisar:\n",
    "\n",
    "* Posts com title vazio\n",
    "* Posts de avaliacao de aplicativo: weather channel? Por enquanto deixar mas avaliar\n",
    "* Posts indice: Vale a pena remover ou nao? Talvez seja algo a analisar.\n",
    "* Lugares que não existem mais. O que fazer?\n",
    "* Posts de roteiro: o que fazer? Patagonia? Islandia? A principio vou manter\n",
    "\n",
    "**Ideia**: Colocar a lista de \"name\" a remover em um arquivo csv e carregar de la porque aqui pode ficar muito grande."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover papel de parede\n",
    "papel_parede = published['name'].str.startswith('papel-de-parede')\n",
    "\n",
    "# Verificar quantos papeis de parede ainda existem\n",
    "(unique, counts) = np.unique(papel_parede, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "# Verificamos que ainda haviam 60 papeis de parede mesmo apos remover os textos menores que 42\n",
    "# frequencies\n",
    "\n",
    "published = published[~papel_parede].reset_index(drop=True) \n",
    "\n",
    "# Ha o caso em que o \"name\" comeca com \"papel-parede\"\n",
    "papel_parede = published['name'].str.startswith('papel-parede')\n",
    "published = published[~papel_parede].reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_remover = [\n",
    "    'recomendamos', 'contato', 'pesquisa-perfil-dos-leitores-do-blog',\n",
    "    'india-folha-dicas-de-sobrevivencia',\n",
    "    'google-oferece-wi-fi-gratis-nos-bares-do-brasil',\n",
    "    'na-midia-nerd-na-puc-tv',\n",
    "    'parceria-mondial-assistance', # comercial\n",
    "    'estude-idiomas-e-fuja-do-silencio', # post patrocinado\n",
    "    'quem-somos',\n",
    "    'tripadvisor-top-25-hoteis', # Publicado em 2012 (temporal) e ainda irrelevante para levantamento de topicos, nao eh conteudo nosso\n",
    "    'infraero-internet-gratuita-nos-aeroportos', # temporal, 2012\n",
    "    'convite-exposicao-fotografica-parques-nacionais-americanos', # temporal, 2012\n",
    "    'exposicao-fotografica-parques-nacionais-americanos', # temporal, 2012\n",
    "    'trip-advisor-vistas-espetaculares-da-cama-do-hotel', # comercial e temporal\n",
    "    'blogs-viajens', # referencia para outros blogs de viagens\n",
    "    'tres-anos-de-nerds-viajantes', # temporal\n",
    "    'relato-assalto-a-mao-armada-em-genipabu', # apoio a conhecidos\n",
    "    'rbbv-rede-brasileira-de-blogueiros-de-viagem', # comercial\n",
    "    'evento-workshop-argentina', # comercial e temporal\n",
    "    'blog-action-day-the-power-of-we', # comercial\n",
    "    'peru-um-pais-a-ser-explorado', # comercial, post patrocinado\n",
    "    'belo-horizonte-feliz-115-anos', # post temporal\n",
    "    'encontro-rede-brasileira-de-blogueiros-de-viagem', # temporal\n",
    "    'acompanhe-todas-as-nossas-atualizacoes-pelo-facebook', # comercial\n",
    "    'blogosfera-viajante-secreto', # temporal\n",
    "    'um-ano-de-nerds-viajantes', # temporal\n",
    "    'sorteio-album-de-fotos-o-segredo-do-vitorio', # comercial\n",
    "    'sorteio-guia-essencial-gramado-e-canela', # comercial\n",
    "    'sorteio-guia-miami-romero-britto', # comercial\n",
    "    'sorteio-de-cape-town-a-muscat-uma-aventura-pela-africa', # comercial\n",
    "    'sorteio-porta-retrato-lata-turista-chic', # comercial\n",
    "    'visitando-aeroporto-viracopos', # temporal e comercial\n",
    "    'concurso-assista-a-final-da-uefa-champions-league-em-wembley', # comercial\n",
    "    'intrip-reserve-exeriencias-viagem', # outros blogs\n",
    "    'nerd-na-globo-bom-dia-minas', # comercial\n",
    "    'voando-com-a-azul-linhas-aereas', # comercial\n",
    "    'estamos-de-volta', # post pessoal e sem conteudo a definir topico\n",
    "    'adventure-bloggers-jalapao-eu-vou', # comercial e temporal\n",
    "    'retrospectiva-2013', # temporal\n",
    "    'dois-anos-de-nerds-viajantes', # temporal\n",
    "    'concurso-cultural-viajar-e', # temporal e comercial\n",
    "    'serra-cipo-fotos-pos-casamento', # pessoal\n",
    "    'livro-guia-essencial-de-curitiba', # comercial\n",
    "    'emirates-airlines-conectando-os-amantes-do-futebol', # comercial\n",
    "    'na-midia-nerds-na-tv-horizonte', # comercial e temporal\n",
    "    'dicas-capa-mala-trippy', # comercial\n",
    "    'na-midia-programa-caleidoscopio-argentina', # temporal e comercial\n",
    "    'desconto-no-seguro-de-viagem-outubro2015', # temporal e comercial\n",
    "    'mondial-assistance-seguro-viagem-desconto', # comercial\n",
    "    'quatro-anos-de-nerds-viajantes', # temporal\n",
    "    'cinco-anos-de-nerds-viajantes', # temporal\n",
    "    'fidelidade-livelo-acumular-pontos' # comercial\n",
    " ]\n",
    "published = published[~published['name'].isin(names_remover)]\n",
    "# published.nsmallest(5, 'n_characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trabalho manual de varrer todos os posts para ver um a um qual poderia ser removido. O criterio, obviamente, nao foi ler os posts mas avaliar pelo proprio name.\n",
    "# 0 a 59 esta ok (tirar papel de parede)\n",
    "# published.iloc[360:][['date', 'title', 'name', 'n_characters']]\n",
    "#published.loc[272]['name']\n",
    "#published.shape"
   ]
  },
  {
   "source": [
    "## Limpeza de conteudo textual"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    text_tokens = word_tokenize(text)\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in pt_stopwords]\n",
    "    return \" \".join(tokens_without_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Remover caption de imagens\n",
    "\"\"\"\n",
    "def remover_caption(text):\n",
    "    clean = re.compile('\\[.*caption.*\\]')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemm_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return \" \".join(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    tokeniser = RegexpTokenizer(r'[A-Za-z]{3,}')\n",
    "    tokens = tokeniser.tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_stopwords = stopwords.words('portuguese')\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    no_html = remove_html_tags(text)\n",
    "    no_sw = remove_stopwords(no_html)\n",
    "    no_caption = remover_caption(no_sw)\n",
    "    stemmed = stemm_text(no_caption)\n",
    "    no_punct = remove_punctuations(stemmed)\n",
    "    preprocessed = no_punct\n",
    "    return preprocessed"
   ]
  },
  {
   "source": [
    "## Treinamento do modelo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate documents\n",
    "documents = published['content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dictionary, mapping words to ids\n",
    "id2word = Dictionary(documents)\n",
    "# id2word.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 2), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 1), (21, 2), (22, 1), (23, 1), (24, 2), (25, 1), (26, 1), (27, 1), (28, 1), (29, 2), (30, 1), (31, 1), (32, 2), (33, 1), (34, 2), (35, 1), (36, 2), (37, 1), (38, 1), (39, 1), (40, 1), (41, 2), (42, 1), (43, 1), (44, 5), (45, 1), (46, 1), (47, 2), (48, 2), (49, 1), (50, 2), (51, 1), (52, 2), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 4), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 2), (85, 1), (86, 1), (87, 1), (88, 13), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 2), (107, 2), (108, 1), (109, 1), (110, 1), (111, 3), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 4), (118, 1), (119, 2), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 3), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 3), (138, 1), (139, 1)]\n"
     ]
    }
   ],
   "source": [
    "# We can see word: word id pairs in this output. For instance, word id = 5 represents ‘mango’. Using the dictionary, we can transform the preprocessed documents into numerical representation:\n",
    "corpus = [id2word.doc2bow(document) for document in documents]\n",
    "print(corpus[0])\n",
    "# Here, we see (word id, word count) pairs for each unique word in the first document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple model\n",
    "num_topics = 5\n",
    "lda = LdaModel(corpus=corpus, id2word=id2word, \n",
    "               num_topics=num_topics, passes=20, \n",
    "               random_state=0)\n",
    "for i in range(num_topics):\n",
    "    print(f\"********** Topic {i+1} **********\")\n",
    "    print(lda.print_topic(i, topn=5), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train size: (373,)\nTest size: (5,)\n"
     ]
    }
   ],
   "source": [
    "# Usually, many consider partitioning dataset in unsupervised modelling has little value as there is no target to check against. However, I think it would be good to set aside a handful of unseen test documents to sense check the model later.\n",
    "X_train, X_test = train_test_split(documents, test_size=5, random_state=1)\n",
    "print(\"Train size:\", X_train.shape)\n",
    "print(\"Test size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of unique words: 1374 \n\nFirst document:  [(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 2), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 2), (15, 1), (16, 1), (17, 2), (18, 1), (19, 1), (20, 1), (21, 1), (22, 2), (23, 1), (24, 1), (25, 2), (26, 1), (27, 2), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 5), (35, 1), (36, 2), (37, 2), (38, 1), (39, 2), (40, 2), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 4), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 2), (66, 1), (67, 1), (68, 13), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 2), (81, 2), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 4), (89, 1), (90, 2), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 3), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 3), (106, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Let’s transform the training documents into numerical representation.\n",
    "\n",
    "# Create word id mappings\n",
    "id2word = Dictionary(documents)\n",
    "id2word.filter_extremes(no_below=5)\n",
    "print('Number of unique words: ' + str(len(id2word.token2id.keys())), '\\n')\n",
    "\n",
    "# Transform documents to numbers\n",
    "corpus = [id2word.doc2bow(document) for document in documents]\n",
    "print('First document: ', corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence(num_topics):\n",
    "    \"\"\"Compute coherence score given a number of topics.\"\"\"\n",
    "    lda = LdaModel(corpus=corpus, id2word=id2word, num_topics=num_topics,\n",
    "        passes=20, random_state=0)\n",
    "    cm = CoherenceModel(model=lda, texts=documents, dictionary=id2word, coherence='c_v')\n",
    "    return cm.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código demora muito para executar\n",
    "coherence = pd.DataFrame(index=range(2,15), columns=['coherence'])\n",
    "for i in coherence.index:\n",
    "    c = compute_coherence(i)\n",
    "    coherence.loc[i, 'coherence'] = c\n",
    "coherence\n",
    "\n",
    "# maiores valores: \n",
    "# 7\t0.502767\n",
    "# 8\t0.496939\n",
    "# 13\t0.493946"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets run an LDA model with 13 topics now\n",
    "num_topics = 13\n",
    "lda = LdaModel(corpus=corpus, id2word=id2word, num_topics=num_topics, passes=20,\n",
    "    random_state=0)\n",
    "\n",
    "def print_lda_topics():\n",
    "    for i in range(num_topics):\n",
    "        print(f\"********** Topic {i+1} **********\")\n",
    "        print(lda.print_topic(i), '\\n')\n",
    "\n",
    "# print_lda_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    id                date                                            content  \\\n",
       "1   11 2012-01-21 12:00:01  No nosso primeiro dia em <a href=\"www.nerdsvia...   \n",
       "3   60 2012-02-24 12:16:22  Sexta-feira em <a href=\"http://www.nerdsviajan...   \n",
       "5  111 2012-02-15 17:41:51  O Palacio de la Moneda, ou somente La Moneda é...   \n",
       "6  134 2012-02-16 11:27:03  Inauguramos hoje a seção <a href=\"http://www.n...   \n",
       "7  167 2012-02-23 22:02:45  O <a href=\"http://www.nerdsviajantes.com/categ...   \n",
       "\n",
       "                                               title  \\\n",
       "1  Santiago - Museu de Arte Pré-Colombiana Fechad...   \n",
       "3              Santiago - Restaurante Aquí Está Coco   \n",
       "5                    Santiago - Palacio de la Moneda   \n",
       "6                       Revelando a Foto - Frutillar   \n",
       "7                 Revelando a Foto - Monument Valley   \n",
       "\n",
       "                                                name            modified  \\\n",
       "1  santiago-museu-de-arte-pre-colombiana-fechado-... 2013-04-19 16:41:23   \n",
       "3                santiago-restaurante-aqui-esta-coco 2013-04-19 18:13:46   \n",
       "5                      santiago-palacio-de-la-moneda 2012-10-13 09:12:49   \n",
       "6                         revelando-a-foto-frutillar 2012-12-26 22:38:13   \n",
       "7                   revelando-a-foto-monument-valley 2013-06-08 08:46:32   \n",
       "\n",
       "   comment_count  n_characters    topic1    topic2  ...    topic4    topic5  \\\n",
       "1              1          3420  0.000513  0.000513  ...  0.052385  0.941973   \n",
       "3              5          5775  0.000845  0.000845  ...  0.000845  0.104439   \n",
       "5              5          4852  0.000658  0.000658  ...  0.000658  0.376247   \n",
       "6              3          2353  0.000836  0.000836  ...  0.697693  0.000836   \n",
       "7              2          2047  0.000819  0.000818  ...  0.483691  0.000819   \n",
       "\n",
       "     topic6    topic7    topic8    topic9   topic10   topic11   topic12  \\\n",
       "1  0.000513  0.000513  0.000513  0.000513  0.000513  0.000513  0.000513   \n",
       "3  0.000845  0.496767  0.000845  0.000845  0.000845  0.000845  0.000845   \n",
       "5  0.000658  0.000658  0.000658  0.000658  0.500454  0.000658  0.000658   \n",
       "6  0.000836  0.000836  0.000836  0.000836  0.293109  0.000836  0.000836   \n",
       "7  0.000819  0.219418  0.000819  0.288706  0.000819  0.000819  0.000819   \n",
       "\n",
       "    topic13  \n",
       "1  0.000513  \n",
       "3  0.000845  \n",
       "5  0.000658  \n",
       "6  0.000836  \n",
       "7  0.000819  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>date</th>\n      <th>content</th>\n      <th>title</th>\n      <th>name</th>\n      <th>modified</th>\n      <th>comment_count</th>\n      <th>n_characters</th>\n      <th>topic1</th>\n      <th>topic2</th>\n      <th>...</th>\n      <th>topic4</th>\n      <th>topic5</th>\n      <th>topic6</th>\n      <th>topic7</th>\n      <th>topic8</th>\n      <th>topic9</th>\n      <th>topic10</th>\n      <th>topic11</th>\n      <th>topic12</th>\n      <th>topic13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>11</td>\n      <td>2012-01-21 12:00:01</td>\n      <td>No nosso primeiro dia em &lt;a href=\"www.nerdsvia...</td>\n      <td>Santiago - Museu de Arte Pré-Colombiana Fechad...</td>\n      <td>santiago-museu-de-arte-pre-colombiana-fechado-...</td>\n      <td>2013-04-19 16:41:23</td>\n      <td>1</td>\n      <td>3420</td>\n      <td>0.000513</td>\n      <td>0.000513</td>\n      <td>...</td>\n      <td>0.052385</td>\n      <td>0.941973</td>\n      <td>0.000513</td>\n      <td>0.000513</td>\n      <td>0.000513</td>\n      <td>0.000513</td>\n      <td>0.000513</td>\n      <td>0.000513</td>\n      <td>0.000513</td>\n      <td>0.000513</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>60</td>\n      <td>2012-02-24 12:16:22</td>\n      <td>Sexta-feira em &lt;a href=\"http://www.nerdsviajan...</td>\n      <td>Santiago - Restaurante Aquí Está Coco</td>\n      <td>santiago-restaurante-aqui-esta-coco</td>\n      <td>2013-04-19 18:13:46</td>\n      <td>5</td>\n      <td>5775</td>\n      <td>0.000845</td>\n      <td>0.000845</td>\n      <td>...</td>\n      <td>0.000845</td>\n      <td>0.104439</td>\n      <td>0.000845</td>\n      <td>0.496767</td>\n      <td>0.000845</td>\n      <td>0.000845</td>\n      <td>0.000845</td>\n      <td>0.000845</td>\n      <td>0.000845</td>\n      <td>0.000845</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>111</td>\n      <td>2012-02-15 17:41:51</td>\n      <td>O Palacio de la Moneda, ou somente La Moneda é...</td>\n      <td>Santiago - Palacio de la Moneda</td>\n      <td>santiago-palacio-de-la-moneda</td>\n      <td>2012-10-13 09:12:49</td>\n      <td>5</td>\n      <td>4852</td>\n      <td>0.000658</td>\n      <td>0.000658</td>\n      <td>...</td>\n      <td>0.000658</td>\n      <td>0.376247</td>\n      <td>0.000658</td>\n      <td>0.000658</td>\n      <td>0.000658</td>\n      <td>0.000658</td>\n      <td>0.500454</td>\n      <td>0.000658</td>\n      <td>0.000658</td>\n      <td>0.000658</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>134</td>\n      <td>2012-02-16 11:27:03</td>\n      <td>Inauguramos hoje a seção &lt;a href=\"http://www.n...</td>\n      <td>Revelando a Foto - Frutillar</td>\n      <td>revelando-a-foto-frutillar</td>\n      <td>2012-12-26 22:38:13</td>\n      <td>3</td>\n      <td>2353</td>\n      <td>0.000836</td>\n      <td>0.000836</td>\n      <td>...</td>\n      <td>0.697693</td>\n      <td>0.000836</td>\n      <td>0.000836</td>\n      <td>0.000836</td>\n      <td>0.000836</td>\n      <td>0.000836</td>\n      <td>0.293109</td>\n      <td>0.000836</td>\n      <td>0.000836</td>\n      <td>0.000836</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>167</td>\n      <td>2012-02-23 22:02:45</td>\n      <td>O &lt;a href=\"http://www.nerdsviajantes.com/categ...</td>\n      <td>Revelando a Foto - Monument Valley</td>\n      <td>revelando-a-foto-monument-valley</td>\n      <td>2013-06-08 08:46:32</td>\n      <td>2</td>\n      <td>2047</td>\n      <td>0.000819</td>\n      <td>0.000818</td>\n      <td>...</td>\n      <td>0.483691</td>\n      <td>0.000819</td>\n      <td>0.000819</td>\n      <td>0.219418</td>\n      <td>0.000819</td>\n      <td>0.288706</td>\n      <td>0.000819</td>\n      <td>0.000819</td>\n      <td>0.000819</td>\n      <td>0.000819</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "# Let’s add the topic probabilities to each training document.\n",
    "def add_probabilities(document):\n",
    "    \"\"\"Add probabilities for topics for a document.\"\"\"\n",
    "    # Preprocess text\n",
    "    # tokens = preprocess_text(document, stop_words)\n",
    "    tokens = preprocess_text(document)\n",
    "    corpus = id2word.doc2bow(tokens)\n",
    "\n",
    "    # Predict probabilities\n",
    "    predictions = lda.get_document_topics(corpus, minimum_probability=0.0)\n",
    "    topics = [topic for topic, probability in predictions]\n",
    "    return [prediction[1] for prediction in predictions]\n",
    "\n",
    "# Add probabilities\n",
    "pd.options.display.max_colwidth = 50\n",
    "train = pd.DataFrame(content)\n",
    "columns = ['topic' + str(i+1) for i in range(num_topics)]\n",
    "train[columns] = train['content'].apply(add_probabilities).to_list()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    id                date                                              title  \\\n",
       "1   11 2012-01-21 12:00:01  Santiago - Museu de Arte Pré-Colombiana Fechad...   \n",
       "3   60 2012-02-24 12:16:22              Santiago - Restaurante Aquí Está Coco   \n",
       "5  111 2012-02-15 17:41:51                    Santiago - Palacio de la Moneda   \n",
       "6  134 2012-02-16 11:27:03                       Revelando a Foto - Frutillar   \n",
       "7  167 2012-02-23 22:02:45                 Revelando a Foto - Monument Valley   \n",
       "\n",
       "                                                name            modified  \\\n",
       "1  santiago-museu-de-arte-pre-colombiana-fechado-... 2013-04-19 16:41:23   \n",
       "3                santiago-restaurante-aqui-esta-coco 2013-04-19 18:13:46   \n",
       "5                      santiago-palacio-de-la-moneda 2012-10-13 09:12:49   \n",
       "6                         revelando-a-foto-frutillar 2012-12-26 22:38:13   \n",
       "7                   revelando-a-foto-monument-valley 2013-06-08 08:46:32   \n",
       "\n",
       "   comment_count  n_characters    topic1    topic2    topic3  ...     top9  \\\n",
       "1              1          3420  0.000513  0.000513  0.000513  ...   topic1   \n",
       "3              5          5775  0.000845  0.000845  0.390339  ...  topic13   \n",
       "5              5          4852  0.000658  0.000658  0.116723  ...   topic8   \n",
       "6              3          2353  0.000836  0.000836  0.000836  ...   topic3   \n",
       "7              2          2047  0.000819  0.000818  0.000819  ...  topic13   \n",
       "\n",
       "      prob9    top10    prob10    top11    prob11    top12    prob12   top13  \\\n",
       "1  0.000513   topic2  0.000513  topic11  0.000513   topic6  0.000513  topic9   \n",
       "3  0.000845  topic11  0.000845   topic8  0.000845   topic2  0.000845  topic9   \n",
       "5  0.000658  topic11  0.000658   topic6  0.000658   topic9  0.000658  topic2   \n",
       "6  0.000836  topic12  0.000836   topic5  0.000836   topic9  0.000836  topic6   \n",
       "7  0.000819   topic8  0.000819   topic1  0.000819  topic12  0.000819  topic2   \n",
       "\n",
       "     prob13  \n",
       "1  0.000513  \n",
       "3  0.000845  \n",
       "5  0.000658  \n",
       "6  0.000836  \n",
       "7  0.000818  \n",
       "\n",
       "[5 rows x 46 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>date</th>\n      <th>title</th>\n      <th>name</th>\n      <th>modified</th>\n      <th>comment_count</th>\n      <th>n_characters</th>\n      <th>topic1</th>\n      <th>topic2</th>\n      <th>topic3</th>\n      <th>...</th>\n      <th>top9</th>\n      <th>prob9</th>\n      <th>top10</th>\n      <th>prob10</th>\n      <th>top11</th>\n      <th>prob11</th>\n      <th>top12</th>\n      <th>prob12</th>\n      <th>top13</th>\n      <th>prob13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>11</td>\n      <td>2012-01-21 12:00:01</td>\n      <td>Santiago - Museu de Arte Pré-Colombiana Fechad...</td>\n      <td>santiago-museu-de-arte-pre-colombiana-fechado-...</td>\n      <td>2013-04-19 16:41:23</td>\n      <td>1</td>\n      <td>3420</td>\n      <td>0.000513</td>\n      <td>0.000513</td>\n      <td>0.000513</td>\n      <td>...</td>\n      <td>topic1</td>\n      <td>0.000513</td>\n      <td>topic2</td>\n      <td>0.000513</td>\n      <td>topic11</td>\n      <td>0.000513</td>\n      <td>topic6</td>\n      <td>0.000513</td>\n      <td>topic9</td>\n      <td>0.000513</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>60</td>\n      <td>2012-02-24 12:16:22</td>\n      <td>Santiago - Restaurante Aquí Está Coco</td>\n      <td>santiago-restaurante-aqui-esta-coco</td>\n      <td>2013-04-19 18:13:46</td>\n      <td>5</td>\n      <td>5775</td>\n      <td>0.000845</td>\n      <td>0.000845</td>\n      <td>0.390339</td>\n      <td>...</td>\n      <td>topic13</td>\n      <td>0.000845</td>\n      <td>topic11</td>\n      <td>0.000845</td>\n      <td>topic8</td>\n      <td>0.000845</td>\n      <td>topic2</td>\n      <td>0.000845</td>\n      <td>topic9</td>\n      <td>0.000845</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>111</td>\n      <td>2012-02-15 17:41:51</td>\n      <td>Santiago - Palacio de la Moneda</td>\n      <td>santiago-palacio-de-la-moneda</td>\n      <td>2012-10-13 09:12:49</td>\n      <td>5</td>\n      <td>4852</td>\n      <td>0.000658</td>\n      <td>0.000658</td>\n      <td>0.116723</td>\n      <td>...</td>\n      <td>topic8</td>\n      <td>0.000658</td>\n      <td>topic11</td>\n      <td>0.000658</td>\n      <td>topic6</td>\n      <td>0.000658</td>\n      <td>topic9</td>\n      <td>0.000658</td>\n      <td>topic2</td>\n      <td>0.000658</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>134</td>\n      <td>2012-02-16 11:27:03</td>\n      <td>Revelando a Foto - Frutillar</td>\n      <td>revelando-a-foto-frutillar</td>\n      <td>2012-12-26 22:38:13</td>\n      <td>3</td>\n      <td>2353</td>\n      <td>0.000836</td>\n      <td>0.000836</td>\n      <td>0.000836</td>\n      <td>...</td>\n      <td>topic3</td>\n      <td>0.000836</td>\n      <td>topic12</td>\n      <td>0.000836</td>\n      <td>topic5</td>\n      <td>0.000836</td>\n      <td>topic9</td>\n      <td>0.000836</td>\n      <td>topic6</td>\n      <td>0.000836</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>167</td>\n      <td>2012-02-23 22:02:45</td>\n      <td>Revelando a Foto - Monument Valley</td>\n      <td>revelando-a-foto-monument-valley</td>\n      <td>2013-06-08 08:46:32</td>\n      <td>2</td>\n      <td>2047</td>\n      <td>0.000819</td>\n      <td>0.000818</td>\n      <td>0.000819</td>\n      <td>...</td>\n      <td>topic13</td>\n      <td>0.000819</td>\n      <td>topic8</td>\n      <td>0.000819</td>\n      <td>topic1</td>\n      <td>0.000819</td>\n      <td>topic12</td>\n      <td>0.000819</td>\n      <td>topic2</td>\n      <td>0.000818</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 46 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "# Now, let’s organise the probabilities. We will create a few new columns:\n",
    "train = train.assign(top1=np.nan, prob1=np.nan, top2=np.nan, \n",
    "                     prob2=np.nan, top3=np.nan, prob3=np.nan,\n",
    "                     top4=np.nan, prob4=np.nan, top5=np.nan, \n",
    "                     prob5=np.nan, top6=np.nan, prob6=np.nan,\n",
    "                     top7=np.nan, prob7=np.nan, top8=np.nan, prob8=np.nan,\n",
    "                     top9=np.nan, prob9=np.nan, top10=np.nan, prob10=np.nan,\n",
    "                     top11=np.nan, prob11=np.nan, top12=np.nan, prob12=np.nan,\n",
    "                     top13=np.nan, prob13=np.nan\n",
    "                     )\n",
    "top_cols = ['top' + str(i) for i in range(1, 14)]\n",
    "prob_cols = ['prob' + str(i) for i in range(1, 14)]\n",
    "for record in train.index:\n",
    "    top = train.loc[record, 'topic1':'topic13'].astype(float).nlargest(13)\n",
    "    train.loc[record, top_cols] = top.index\n",
    "    train.loc[record, prob_cols] = top.values\n",
    "train.drop(columns='content').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let’s visualise the probability distribution for the most dominant topic. Ideally, we prefer if most probabilities are centered around higher value.\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.kdeplot(data=train, x='prob1', hue='top1', shade=True, common_norm=False)\n",
    "plt.title('Probability of dominant topic colour coded by topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great to see that majority of the values are close to 1. Let’s inspect the summary stats for the probability values:\n",
    "train[prob_cols].describe()\n",
    "# Median probability for the most dominant topic is 0.9466. That’s awesome!"
   ]
  },
  {
   "source": [
    "## Topics probability for Melhores Destinos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repository.melhores_destinos import get_promocoes\n",
    "from cleanning.melhores_destinos_cleanner import clean_melhores_destinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "prom = get_promocoes()\n",
    "prom = clean_melhores_destinos(prom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s add the topic probabilities to each training document.\n",
    "def add_probabilities_melhores_destinos(texto_prom):\n",
    "    \"\"\"Add probabilities for topics for a document.\"\"\"\n",
    "    corpus = id2word.doc2bow(tokens)\n",
    "\n",
    "    # Predict probabilities\n",
    "    predictions = lda.get_document_topics(corpus, minimum_probability=0.0)\n",
    "    topics = [topic for topic, probability in predictions]\n",
    "    return [prediction[1] for prediction in predictions]\n",
    "\n",
    "# Add probabilities\n",
    "pd.options.display.max_colwidth = 50\n",
    "train = pd.DataFrame(content)\n",
    "columns = ['topic' + str(i+1) for i in range(num_topics)]\n",
    "train[columns] = train['content'].apply(add_probabilities).to_list()\n",
    "train.head()"
   ]
  }
 ]
}