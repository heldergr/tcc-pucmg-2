{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('tcc-venv': venv)"
  },
  "interpreter": {
   "hash": "e40f5302c6d4b9de2141353283620edefcabae1dbe23ed7117377b1c1ce32e40"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Wikipedia"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from coleta.corretor_paginas_wikipedia import CorretorEstruturaCategorias\n",
    "from coleta.wikipedia import CategoriaCollector, PaginaCollector, WikipediaDownloader\n",
    "from urllib.parse import urlencode\n",
    "from pymongo import MongoClient\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "wikipedia_downloader = WikipediaDownloader()\n",
    "pagina_collector = PaginaCollector(collection_paginas='pages_brasil', collection_paginas_conteudo='pages_content_brasil')\n",
    "categoria_collector = CategoriaCollector(collection_categorias='categories_brasil', pagina_collector=pagina_collector)\n",
    "country = 'Brasil'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Definir categoria raiz\n",
    "\n",
    "Em nosso caso de estudo a categoria raiz sera Geografia do Brasil. Abaixo esta o documento correspondente, obtido atraves de procura feita \n",
    "no resultado da consulta de category_members da categoria \"Categoria:Brasil\"."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "is_adicionar_categoria_raiz = False\n",
    "if is_adicionar_categoria_raiz:\n",
    "    categoria_geografia_brasil = {'pageid': 15122,\n",
    "    'ns': 14,\n",
    "    'title': 'Categoria:Geografia do Brasil',\n",
    "    'type': 'subcat', \n",
    "    'country': 'Brasil'}\n",
    "    categoria_collector.add_categories_for_check([categoria_geografia_brasil])\n",
    "# category_members = wikipedia_downloader.get_category_members(cmtitle='Categoria:Brasil')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Iteração de download de categorias\n",
    "\n",
    "- Categories status\n",
    "    * Check: waiting for someone to check if it has to be downloaded\n",
    "    * Waiting: waiting for dowload\n",
    "    * Skeep: skeep download of this category\n",
    "    * Done: downloaded"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Passo 1 - Procurar categorias candidatas a download"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "categorias_candidatas_para_download = categoria_collector.get_categories_for_check()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for ccpd in categorias_candidatas_para_download[:10]:\n",
    "    print(f'{ccpd[\"pageid\"]} - {ccpd[\"title\"]}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Passo 2 - Selecionar para download e skeep"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "categorias_selecionadas_para_download = []\n",
    "if len(categorias_selecionadas_para_download) > 0:\n",
    "    categoria_collector.set_categories_for_download(categorias_selecionadas_para_download)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "categorias_selecionadas_para_skeep = []\n",
    "if len(categorias_selecionadas_para_skeep) > 0:\n",
    "    categoria_collector.set_categories_for_skeep(categorias_selecionadas_para_skeep)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Passo 3 - Fazer download de selecionadas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "categorias_para_download = categoria_collector.get_categories_for_download()\n",
    "print(f'{len(categorias_para_download)} categorias recuperadas para download...')\n",
    "for cpd in categorias_para_download:\n",
    "    categoria_collector.download_category_tree(cpd, cpd['country'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Corrigir estrutura de categorias"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# corretor_estrutura_categorias = CorretorEstruturaCategorias(collection_name_incorreto='', collection_correto='')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download de páginas (wikitext)\n",
    "\n",
    "- Pages status (wikitext)\n",
    "    * Waiting: waiting for download\n",
    "    * Done: Download done"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Executar apenas uma vez\n",
    "# pagina_collector.set_pages_for_wikitext_download()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "paginas_download_wikitext = pagina_collector.get_pages_for_download()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pagina_collector.run_wikitext_download(5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download de páginas (text)\n",
    "\n",
    "- Pages status (text)\n",
    "    * Waiting: waiting for download\n",
    "    * Donw: Download done"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Executar apenas uma vez\n",
    "# pagina_collector.set_pages_for_text_download()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "keep_running = True\n",
    "while keep_running:\n",
    "    amount_done = pagina_collector.run_text_download(5)\n",
    "    keep_running = amount_done > 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Backup do que já foi feito download"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "run_backup = False\n",
    "if run_backup:\n",
    "    categories = list(mongo_categories.find())\n",
    "    categories_df = pd.DataFrame(categories)\n",
    "    categories_df.to_csv('categories.csv')\n",
    "\n",
    "    pages = list(mongo_pages.find())\n",
    "    pages_df = pd.DataFrame(pages)\n",
    "    pages_df.to_csv('pages.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Verificar categorias e páginas sem country"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Pages\n",
    "pages_no_country = list(db.pages.find({\"country\": {\"$exists\": False }}))\n",
    "print(f'{len(pages_no_country)} pages found with no country')\n",
    "\n",
    "# Categories\n",
    "categories_no_country = list(db.categories.find({\"country\": {\"$exists\": False }}))\n",
    "print(f'{len(categories_no_country)} categories found with no country')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def show_download_statistics():\n",
    "    pdc = get_pages_downloads_counts()\n",
    "    print(f'Page download counts: {pdc}')\n",
    "    pages_wikitext_counts = mongo_content.count_documents({})\n",
    "    print(f'Pages with wikitext: {pages_wikitext_counts}')\n",
    "# show_download_statistics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download page texts"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "run_text_download(303)\n",
    "show_text_download_statistics()"
   ],
   "outputs": [],
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pcs = list(mongo_content.aggregate(\n",
    "    [ \n",
    "        { '$group': { '_id': '$pageid', 'total': { '$sum': 1 } } }\n",
    "    ]\n",
    "))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dobrado = [p for p in pcs if p['total'] > 1]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def find_distinct_pages():\n",
    "    return list(mongo_pages.aggregate(\n",
    "        [ \n",
    "            { '$group': { '_id': '$pageid', 'total': { '$sum': 1 } } },\n",
    "            { '$sort': { 'total': -1 }}\n",
    "        ]\n",
    "    ))\n",
    "\n",
    "def count_distinct_pages():\n",
    "    return len(find_distinct_pages())\n",
    "\n",
    "print(f'We have downloaded {count_distinct_pages()} distinct pages')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "list(mongo_pages.find({ 'pageid': 158914 }))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pages_dobrado = [p for p in pcs if p['total'] > 1]\n",
    "pages_dobrado[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "list(mongo_pages.find({'pageid': 237330}))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correção collection pages\n",
    "\n",
    "- Problema: a mesma página tinha sido baixada mais de uma vez porque era referenciada por várias coleções\n",
    "- Solução\n",
    "    * Renomear collection pages para pages_incorreto (feito no mongo shell)\n",
    "    * Recriar a collection pages com estrutura correta\n",
    "        * A categoria agora será um objeto com id e título ao invés de estes valores estarem soltos na páginas. Assim ficará melhor estuturado\n",
    "        * O objeto da página terá uma collection de categorias. Cada página lida da estrutura antiga terá na nova collection um array com as categorias que a referenciam\n",
    "    * Renomear pages_content para pages_content incorreto"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "mongo_client = MongoClient()\n",
    "db = mongo_client.wikipedia\n",
    "collection_incorreto = db['pages_brasil_incorreto']\n",
    "collection_correto = db['pages_brasil']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Obtem todas paginas de collection incorreta\n",
    "todas_paginas_incorreto = list(collection_incorreto.find({}))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def criar_objetos_categoria(todas_paginas_incorreto):\n",
    "    # Corrigir categoria das paginas incorretas. Cria objeto para categoria e coloca id e titulo\n",
    "    for pagina_incorreto in todas_paginas_incorreto:\n",
    "        category = {\n",
    "            'category_id': pagina_incorreto['category_id'],\n",
    "            'category_title': pagina_incorreto['category_title']\n",
    "        }\n",
    "        pagina_incorreto['category'] = category\n",
    "        del pagina_incorreto['category_id']\n",
    "        del pagina_incorreto['category_title']\n",
    "    return todas_paginas_incorreto\n",
    "\n",
    "todas_paginas_incorreto = criar_objetos_categoria(todas_paginas_incorreto)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def agregar_categorias_por_pagina(todas_paginas_incorreto):\n",
    "    # Dictionario que mapeia uma pageid para documento da pagina\n",
    "    agregado_paginas_incorreto = {}\n",
    "\n",
    "    for pagina_incorreto in todas_paginas_incorreto:\n",
    "        pageid_incorreto = pagina_incorreto['pageid']\n",
    "        if pageid_incorreto in agregado_paginas_incorreto:\n",
    "            existente = agregado_paginas_incorreto[pageid_incorreto]\n",
    "            existente['categories'].append(pagina_incorreto['category'])\n",
    "        else:\n",
    "            pagina_incorreto['categories'] = [pagina_incorreto['category']]\n",
    "            agregado_paginas_incorreto[pageid_incorreto] = pagina_incorreto\n",
    "        del pagina_incorreto['category']\n",
    "    \n",
    "    return agregado_paginas_incorreto\n",
    "\n",
    "agregado_paginas_incorreto = agregar_categorias_por_pagina(todas_paginas_incorreto)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Insere as páginas corrigidas no mongo\n",
    "paginas_agregadas = list(agregado_paginas_incorreto.values())\n",
    "collection_correto.insert_many(paginas_agregadas)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Conta páginas para ver o resultado\n",
    "print(collection_correto.count_documents({}))\n",
    "print(collection_incorreto.count_documents({}))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Análise documentos download"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Análise wikitext"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pcs = list(mongo_content.find({}))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lengths_wikitext = [len(pc['wikitext']) for pc in pcs]\n",
    "df = pd.DataFrame(lengths_wikitext, columns=['Length'])\n",
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.displot(df, x='Length', bins=20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Verificando se todas as páginas srealmente têm conteúdo\n",
    "df['Length'].describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fix downloaded text\n",
    "\n",
    "- It was stored in the documents the whole structure of the answer\n",
    "- It should store only the ext"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pcs = list(mongo_content.find({}))\n",
    "for pc in pcs:\n",
    "    mongo_content.update_one(\n",
    "        { 'pageid': pc['pageid'] },\n",
    "        { '$set': { 'text': pc['text']['parse']['text'] } }\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Análise text"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pcs = list(mongo_content.find({}))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lengths_text = [len(pc['text']) for pc in pcs]\n",
    "df = pd.DataFrame(lengths_text, columns=['Length'])\n",
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.displot(df, x='Length', bins=20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Verificando se todas as páginas srealmente têm conteúdo\n",
    "df['Length'].describe()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}