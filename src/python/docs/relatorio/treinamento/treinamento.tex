\section{Treinamento de modelo}

O treinamento tem como objetivo fazer o ajuste de um modelo que identifique os tópicos que compôem um conjunto de textos (\textit{corpus})
e que seja capaz de encontrar os tópicos mais importantes na definição do conteúdo dos textos. A lista de tópicos dos textos, com suas respectivas 
probabilidades, serão o insumo para o cálculo de semalhança entre os documentos, conforme veremos mais adiante.

\subsection{LDA - Latent Dirichlet Allocation}

LDA é um algoritmo de aprendizado não supervisionado que associa tópicos a documentos. Documentos são como textos e cada um pode conter mais de um 
tópico, assim como um tópico pode estar presente em vários documentos. Tópicos são formados por palavras e uma mesma palavra pode fazer parte de mais de um tópico, ou seja, uma mesma palavra contribui para a formação de vários 
tópicos. Os tópicos são descobertos durante o treinamento do modelo mas a quantidade de tópicos deve ser especificada a priori (é um dos parâmetros de ajuste).

Após o treinamento do modelo um documento tem uma distribuição discreta de tópicos e um tópico tem uma distribuição discreta de palavras. Na seção
\textit{Testes de análise de tópicos} há exemplos de topicos extraídos dos documentos da base de treinamento, assim como palavras que contribuem
na definição dos tópicos.

Há vários tipos de uso para o algoritmo LDA, como entender melhor o tipo de documento um determinado conjunto de palavras (notícias, artigo na wikipedia, 
negócios), quantificar as palavras mais usadas e mais importantes em um texto ou mesmo encontrar semelhanças e recomendações de documentos. 

Neste trabalho eu usei LDA para definir a distribuição de tópicos em textos (e consequentemente das palavras destes tópicos) e com base 
no modelo ajustado calculei a semalhança entre textos de acordo com as probabilidades dos tópicos do modelo treinado encontrados para os documentos
das bases de treinamento e comparação. Enfim, com base nestas probabilidades eu calculei a distância entre os documentos e 
fiz o cálculo de recomendações de textos novos considerados semelhantes aos da base de treinamento.

LDA não tem boa performance com documentos curtos, como tweets, por exemplo, pois ele infere parâmetros a partir da observação de palavras e se não há palavras
suficientes não há as condições necessárias para um bom aproveitamento. O algoritmo trabalha com modelos do tipo bag of words, ou seja, 
não há importância na ordem das palavras. Outros algoritmos funcionam bem com sentenças estruturadas.

\subsubsection{Hiperparâmetros}

Há vários parâmetros que podemos variar no treinamento de um modelo com LDA mas além do número de tópicos eu resolvi variar os seguintes hiperparâmetros:

\begin{itemize}
    \item $\alpha$ (alpha): Um valor baixo indica que documentos contém poucos tópicos contribuindo para os mesmos
    \item $\eta$ (eta): Um valor baixo indica que tópicos contém poucas palavras contribuindo para os mesmos, enquanto em um valor alto pode haver maior sobreposição 
    de palavras entre tópicos diferentes
    \item passes: Número de vezes que o algoritmo passa por cada documento no levantamento de tópicos
\end{itemize}

\subimport{./}{analise_coerencia.tex}

\subimport{./}{analise_topicos.tex}